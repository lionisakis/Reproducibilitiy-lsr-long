# @package _global_
defaults:
  - ../dataset@eval_dataset: msmarco_doc_pairs
  - override /dataset@train_dataset: msmarco_doc_triplets
  - override /model: reranker_qmlp_dmlm_long
exp_name: reranker_qmlp_dmlm_msmarco_doc_ce_5_psg_long
train_dataset:
  query_path: "data/msmarco_doc/msmarco-doctrain-queries_long_dataset.tsv"
  collection_path: "data/msmarco_doc/collection_psgs.tsv"
  triplet_path: "data/msmarco_doc/train_triplets_long_dataset.tsv"
  num_psg: 5
eval_dataset:
  num_psgs: 5
  query_path: "data/msmarco_doc/msmarco-docdev-queries_long_dataset.tsv"
  run_path: "./data/msmarco_doc/run_max_score_1_keep_200_long_dataset.trec"
  qrel_path: "data/msmarco_doc/msmarco-docdev-qrels_long_dataset.tsv" 
training_arguments: 
  per_device_train_batch_size: 16
  max_steps: 150000
  gradient_accumulation_steps: 1
  # dataset@eval_dataset: msmarco_rerank
data_collator:
  _target_: lsr.datasets.multi_psgs_triplets.MutiPSGsTripletsBatching
  tokenizer: ${tokenizer}
  
eval_collator: 
  _target_: lsr.datasets.multi_psgs_pairs.MutiPSGsPairsBatching
  tokenizer: ${tokenizer}

trainer: 
  eval_collator: ${eval_collator}
  eval_dataset: ${eval_dataset}

wandb:
  setup:
    project: lsr-framework-phrase
