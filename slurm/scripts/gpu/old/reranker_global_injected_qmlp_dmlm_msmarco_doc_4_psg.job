#!/bin/bash
#SBATCH --nodes 1
#SBATCH -p gpu
#SBATCH --gres gpu:1
#SBATCH -t 00-10:00:00
#SBATCH --job-name g_i_s_4
#SBATCH --mem 256G
#SBATCH -o slurm/output/out/reranker_global_injected_qmlp_dmlm_msmarco_doc_4_psg.out
#SBATCH -e slurm/output/err/reranker_global_injected_qmlp_dmlm_msmarco_doc_4_psg.err
# Make conda available:
module purge
module load 2022
module load Miniconda3/4.12.0
module load CUDA/11.7.0
module load Java/11.0.2

export MAVEN_HOME=../maven/apache-maven-3.8.6/
export PATH=$MAVEN_HOME/bin:$PATH 

# Activate a conda environment:

source activate lsr
python -m lsr.train +experiment=reranker_global_injected_qmlp_dmlm_msmarco_doc_4_psg training_arguments.fp16=True  +training_arguments.learning_rate=0.001 training_arguments.max_steps=60000 +model.window_sizes=[1,2] +model.proximity=8 training_arguments.evaluation_strategy="steps" +training_arguments.eval_steps=20000 training_arguments.save_steps=20000 +training_arguments.save_total_limit=2 +training_arguments.metric_for_best_model="RR@10"