#!/bin/bash
#SBATCH --partition gpu
#SBATCH --ntasks=1
#SBATCH --gres gpu:1
#SBATCH --cpus-per-task 5
#SBATCH --time 0-01:00:00
#SBATCH --job-name=in_msm_q
#SBATCH --output slurm/output/out/query_inference/inference_msmarco_quer.out
#SBATCH --error slurm/output/err/query_inference/inference_msmarco_quer.err

module purge
module load 2022
module load Miniconda3/4.12.0
module load CUDA/11.7.0
module load Java/11.0.2

export MAVEN_HOME=../maven/apache-maven-3.8.6/
export PATH=$MAVEN_HOME/bin:$PATH 

# Activate a conda environment:
source activate lsr 

trap "trap ' ' TERM INT; kill -TERM 0; wait" TERM INT
input_path=data/msmarco_doc/msmarco-docdev-queries.tsv
output_path=data/msmarco_doc/query.tsv
batch_size=128
type='query'
python -m lsr.inference --inp $input_path --out $output_path --type $type --bs $batch_size
wait
