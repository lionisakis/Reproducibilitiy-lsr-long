#!/bin/bash

#SBATCH --partition=rome
#SBATCH --job-name=sum_rep_tr
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=16
#SBATCH --time=03:55:00
#SBATCH --output=./slurm/output/out/document_inference/aggregate_rep_trec_robust_doc_sum_%a_%j.out
#SBATCH --error=./slurm/output/err/document_inference/aggregate_rep_trec_robust_doc_sum_%a_%j.err
#SBATCH --array 1-5%5

module purge
module load 2022
module load Miniconda3/4.12.0
module load Java/11.0.2

export MAVEN_HOME=../maven/apache-maven-3.8.6/
export PATH=$MAVEN_HOME/bin:$PATH 

source activate lsr

input_dir=./data/trec-robust04
aggr="sum"
echo "Exp results" > $output_file

n=$SLURM_ARRAY_TASK_ID
echo "Aggregating $n passages"
output_file=${input_dir}/results_${aggr}_${n}.txt
rm -r ${input_dir}/index_${aggr}_${n}
rm -r ${input_dir}/doc_vectors_${aggr}_${n}
mkdir ${input_dir}/doc_vectors_${aggr}_${n}

for f in $input_dir/doc_vectors/*; do 
    srun python lsr/long_documents/aggregate_long_documents.py $f ${aggr}_${n} ${aggr} $n
    # pids="$pids $!"
done
wait

echo Done processing documents

../anserini-lsr/target/appassembler/bin/IndexCollection -collection JsonSparseVectorCollection -input ${input_dir}/doc_vectors_${aggr}_${n}  -index ${input_dir}/index_${aggr}_${n}  -generator SparseVectorDocumentGenerator -threads 200 -impact -pretokenized

../anserini-lsr/target/appassembler/bin/SearchCollection -index ${input_dir}/index_${aggr}_${n}  -topics ${input_dir}/query.tsv -topicreader TsvString -output ${input_dir}/runs/trec_robust_${aggr}_${n}.trec  -impact -pretokenized -hits 1000 -parallelism 200

echo $n >> $output_file

ir_measures data/trec-robust04/robust04.qrels ${input_dir}/runs/trec_robust_${aggr}_${n}.trec MRR@10 NDCG@10 R@1000 >> $output_file

